{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert finetuning on MRPC data\n",
    "Pytorch + TensorFlow 2.0\n",
    "\n",
    "https://github.com/huggingface/transformers#quick-tour-tf-20-training-and-pytorch-interoperability\n",
    "\n",
    "Paraphrasing task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "from transformers import *\n",
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  9 11:48:00 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:17:00.0 Off |                  N/A |\r\n",
      "|  0%   32C    P8     9W / 275W |     12MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:65:00.0 Off |                  N/A |\r\n",
      "|  0%   31C    P8    11W / 275W |     29MiB / 11176MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1      2159      G   /usr/lib/xorg/Xorg                             9MiB |\r\n",
      "|    1      2304      G   /usr/bin/gnome-shell                           6MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/shivangi/tensorflow_datasets/glue/mrpc/1.0.0\n",
      "INFO:absl:Reusing dataset glue (/home/shivangi/tensorflow_datasets/glue/mrpc/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /home/shivangi/tensorflow_datasets/glue/mrpc/1.0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_val = 64\n",
    "# Load dataset, tokenizer, model from pretrained model/vocabulary\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
    "data = tensorflow_datasets.load('glue/mrpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108311810"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\n",
    "valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\n",
    "train_dataset = train_dataset.shuffle(100).batch(batch_size_train).repeat(2)\n",
    "valid_dataset = valid_dataset.batch(batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "\n",
    "learning_rate = 3e-5 #1e-5 2e-5 3e-5 5e-5\n",
    "epsilon = 1e-08\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 493s 4s/step - loss: 0.5682 - accuracy: 0.6965 - val_loss: 0.4753 - val_accuracy: 0.7843\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate using tf.keras.Model.fit()\n",
    "\n",
    "# history = model.fit(train_dataset, epochs=3, steps_per_epoch=115,\n",
    "#                     validation_data=valid_dataset, validation_steps=7)\n",
    "epochs = 1 #3\n",
    "train_data_size = 3668\n",
    "steps_per_epoch = int(train_data_size / batch_size_train)\n",
    "history = model.fit(train_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=valid_dataset, validation_steps=7,\n",
    "                   callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-65bd98f949e4c22b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-65bd98f949e4c22b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorFlow model in PyTorch for inspection\n",
    "model.save_pretrained('./save/')\n",
    "pytorch_model = BertForSequenceClassification.from_pretrained('./save/', from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_1 is not a paraphrase of sentence_0\n",
      "sentence_2 is a paraphrase of sentence_0\n"
     ]
    }
   ],
   "source": [
    "# Quickly test a few predictions - MRPC is a paraphrasing task, let's see if our model learned the task\n",
    "sentence_0 = \"This is wrong.\"\n",
    "sentence_1 = \"that was right.\"\n",
    "sentence_2 = \"This is incorrect.\"\n",
    "inputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='pt')\n",
    "inputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "pred_1 = pytorch_model(inputs_1['input_ids'], token_type_ids=inputs_1['token_type_ids'])[0].argmax().item()\n",
    "pred_2 = pytorch_model(inputs_2['input_ids'], token_type_ids=inputs_2['token_type_ids'])[0].argmax().item()\n",
    "\n",
    "print(\"sentence_1 is\", \"a paraphrase\" if pred_1 else \"not a paraphrase\", \"of sentence_0\")\n",
    "print(\"sentence_2 is\", \"a paraphrase\" if pred_2 else \"not a paraphrase\", \"of sentence_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trial and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.sparse.Embedding'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.normalization.LayerNorm'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertEmbeddings'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertSelfAttention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertSelfOutput'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertAttention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertIntermediate'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertOutput'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertLayer'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertEncoder'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertPooler'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertModel'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertForSequenceClassification'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivangi/miniconda3/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1)\n",
    "inputs = torch.tensor(inputs).to(torch.int64)\n",
    "macs, params = profile(pytorch_model,(inputs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171052032.0 85609730.0\n"
     ]
    }
   ],
   "source": [
    "print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.sparse.Embedding'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.normalization.LayerNorm'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertEmbeddings'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertSelfAttention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertSelfOutput'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertAttention'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertIntermediate'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertOutput'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertLayer'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertEncoder'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Tanh'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertPooler'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'transformers.modeling_bert.BertModel'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivangi/miniconda3/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 1)\n",
    "inputs = torch.tensor(inputs).to(torch.int64)\n",
    "macs, params = profile(model_new,(inputs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85524480.0 85608192.0\n"
     ]
    }
   ],
   "source": [
    "print(macs,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [module for module in model_new.modules() if type(module) != torch.nn.Sequential]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model_new.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235334\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(len(params)):\n",
    "    #print (params[i][0], len(params[i][1]))\n",
    "    total += len(params[i][1])\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
